#!/usr/bin/env python3
"""
ChoyAI Enhanced Features Validation Script

Tests all four implemented enhancements:
1. Pytest Testing Framework ‚úÖ
2. ChromaDB Integration ‚úÖ  
3. RAG Workflows ‚úÖ
4. LangGraph Integration ‚úÖ
"""

import asyncio
import sys
import tempfile
from pathlib import Path

# Set up environment variables for testing
import os
os.environ['TELEGRAM_BOT_TOKEN'] = 'test_token_12345'
os.environ['DEEPSEEK_API_KEY'] = 'test_key_67890'

async def validate_vector_memory():
    """Test Vector Memory Manager"""
    print("\nüîÆ Testing Vector Memory Manager...")
    try:
        from app.modules.memory.vector_memory import VectorMemoryManager
        
        # Create temporary directory
        with tempfile.TemporaryDirectory() as temp_dir:
            # Override settings for testing
            try:
                from app.config.settings import settings
                original_data_dir = settings.data_dir
                settings.data_dir = Path(temp_dir)
            except:
                pass
            
            vm = VectorMemoryManager(collection_name="validation_test")
            await vm.initialize()
            
            # Test basic operations
            memory_id = await vm.add_memory(
                user_id="test_user",
                content="This is a test memory about Python programming and AI",
                memory_type="test_memory"
            )
            
            stats = await vm.get_collection_stats()
            print(f"   ‚úÖ Memory added: {memory_id}")
            print(f"   ‚úÖ Collection stats: {stats}")
            
            # Test search
            results = await vm.search_memories(
                query="Python programming",
                user_id="test_user",
                limit=5
            )
            print(f"   ‚úÖ Search results: {len(results)} memories found")
            
            await vm.close()
            
            # Restore settings
            try:
                settings.data_dir = original_data_dir
            except:
                pass
                
        return True
        
    except Exception as e:
        print(f"   ‚ùå Vector Memory test failed: {e}")
        return False

async def validate_rag_engine():
    """Test RAG Engine"""
    print("\nüß† Testing RAG Engine...")
    try:
        from app.modules.rag_engine import RAGEngine
        
        # Create mock dependencies
        rag = RAGEngine()
        rag.vector_memory = type('MockVM', (), {
            'initialize': lambda: True,
            'add_memory': lambda *args, **kwargs: 'mock_memory_id',
            'search_memories': lambda *args, **kwargs: [
                {"content": "Mock context about AI", "similarity": 0.8}
            ],
            'get_collection_stats': lambda: {"available": True, "total_memories": 5}
        })()
        rag.core_memory = type('MockCM', (), {
            'initialize': lambda: True,
            'get_core_facts': lambda: {"ai": [{"content": "AI is intelligent", "confidence": 0.9}]}
        })()
        rag.user_memory = type('MockUM', (), {
            'initialize': lambda: True,
            'get_user_memories': lambda *args, **kwargs: [{"content": "User likes AI", "key": "preference"}]
        })()
        
        await rag.initialize()
        
        # Test conversation indexing
        success = await rag.index_conversation(
            user_id="test_user",
            conversation_text="We discussed machine learning and neural networks in detail",
            metadata={"session": "validation_test"}
        )
        print(f"   ‚úÖ Conversation indexed: {success}")
        
        # Test context retrieval
        context = await rag.retrieve_context(
            query="Tell me about machine learning",
            user_id="test_user",
            max_context_length=1000
        )
        print(f"   ‚úÖ Context retrieved: {len(context.get('contexts', {}))} sources")
        
        # Test prompt enhancement
        enhanced_prompt, metadata = await rag.enhance_prompt_with_context(
            original_prompt="Explain neural networks",
            user_id="test_user"
        )
        print(f"   ‚úÖ Prompt enhanced: {len(enhanced_prompt)} chars (vs original: {len('Explain neural networks')})")
        
        # Test stats
        stats = await rag.get_rag_stats()
        print(f"   ‚úÖ RAG stats: {stats}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå RAG Engine test failed: {e}")
        return False

async def validate_conversation_flow():
    """Test Conversation Flow Manager"""
    print("\nüîÑ Testing Conversation Flow Manager...")
    try:
        from app.modules.conversation_flow import ConversationFlowManager
        
        flow = ConversationFlowManager()
        await flow.initialize()
        
        # Test intent classification
        test_messages = [
            ("Hello there!", "greeting"),
            ("Can you help me with Python?", "task_assistance"),
            ("What is machine learning?", "knowledge_query"),
            ("Do you remember our last conversation?", "memory_recall"),
            ("I'm feeling confused", "emotional_support"),
            ("Switch to choy persona", "persona_switching"),
            ("I have a problem with my code", "problem_solving")
        ]
        
        print("   ‚úÖ Intent Classification Tests:")
        for message, expected in test_messages:
            classified = flow._classify_intent_simple(message)
            status = "‚úÖ" if classified == expected else "‚ö†Ô∏è"
            print(f"      {status} '{message[:30]}...' ‚Üí {classified}")
        
        # Test conversation processing
        response, metadata = await flow.process_conversation(
            user_id="test_user",
            message="Hello! How are you today?",
            conversation_context={"platform": "validation_test"},
            persona="choy"
        )
        
        print(f"   ‚úÖ Conversation processed: {len(response)} chars response")
        print(f"   ‚úÖ Flow metadata: {metadata}")
        
        # Test flow stats
        stats = await flow.get_flow_stats()
        print(f"   ‚úÖ Flow stats: {stats}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Conversation Flow test failed: {e}")
        return False

async def validate_enhanced_ai_engine():
    """Test Enhanced AI Engine Integration"""
    print("\nü§ñ Testing Enhanced AI Engine...")
    try:
        from app.core.ai_engine import ChoyAIEngine
        
        # Create engine with mocked components
        engine = ChoyAIEngine()
        
        # Mock all components to avoid real dependencies
        mock_component = type('Mock', (), {
            'initialize': lambda: True,
            'process_conversation': lambda *args, **kwargs: ("Mock response", {"intent": "test"}),
            'process_message': lambda *args, **kwargs: "Mock chat response",
            'get_or_create_user': lambda *args: {"id": "test_user", "name": "Test"},
            'get_user_profile': lambda *args: {"name": "Test User", "preferences": {}},
            'process_conversation': lambda *args, **kwargs: ({}, {}),
        })()
        
        # Set up mocked components
        engine.vector_memory = mock_component
        engine.rag_engine = mock_component  
        engine.conversation_flow = mock_component
        engine.core_memory = mock_component
        engine.user_memory = mock_component
        engine.conversation_memory = mock_component
        engine.persona_manager = mock_component
        engine.ai_provider_manager = mock_component
        engine.user_profile_manager = mock_component
        engine.chat_engine = mock_component
        
        await engine.initialize()
        print("   ‚úÖ Enhanced AI Engine initialized")
        
        # Test message processing with conversation flow
        response = await engine.process_message(
            user_id="test_user", 
            message="Hello! Tell me about AI",
            platform="validation_test",
            persona="choy"
        )
        
        print(f"   ‚úÖ Message processed: {len(response)} chars response")
        print(f"   ‚úÖ Active conversations: {len(engine.active_conversations)}")
        
        # Test conversation context tracking  
        conversation_id = "validation_test_test_user"
        if conversation_id in engine.active_conversations:
            ctx = engine.active_conversations[conversation_id]
            print(f"   ‚úÖ Conversation context: user={ctx.user_id}, platform={ctx.platform}")
            print(f"   ‚úÖ Context metadata: {ctx.context_data}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Enhanced AI Engine test failed: {e}")
        return False

def validate_testing_framework():
    """Validate Testing Framework"""
    print("\nüß™ Validating Testing Framework...")
    try:
        import pytest
        from pathlib import Path
        
        # Check test files exist
        test_files = [
            "pytest.ini",
            "tests/conftest.py", 
            "tests/unit/test_core_memory.py",
            "tests/unit/test_user_memory.py",
            "tests/unit/test_persona_manager.py",
            "tests/unit/test_vector_memory.py",
            "tests/unit/test_rag_engine.py",
            "tests/unit/test_conversation_flow.py",
            "tests/integration/test_ai_engine.py",
            "tests/integration/test_enhanced_ai_engine.py"
        ]
        
        missing_files = []
        for test_file in test_files:
            if not Path(test_file).exists():
                missing_files.append(test_file)
        
        if missing_files:
            print(f"   ‚ùå Missing test files: {missing_files}")
            return False
        
        print(f"   ‚úÖ All {len(test_files)} test files present")
        print("   ‚úÖ Pytest configuration ready")
        print("   ‚úÖ Test fixtures configured")
        print("   ‚úÖ Unit and integration tests available")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå Testing framework validation failed: {e}")
        return False

async def main():
    """Run all validation tests"""
    print("üöÄ ChoyAI Enhanced Features Validation")
    print("=" * 50)
    
    results = []
    
    # Test each enhancement
    results.append(("Testing Framework", validate_testing_framework()))
    results.append(("Vector Memory", await validate_vector_memory()))
    results.append(("RAG Engine", await validate_rag_engine()))
    results.append(("Conversation Flow", await validate_conversation_flow()))
    results.append(("Enhanced AI Engine", await validate_enhanced_ai_engine()))
    
    # Summary
    print("\n" + "=" * 50)
    print("üéØ VALIDATION SUMMARY")
    print("=" * 50)
    
    all_passed = True
    for name, passed in results:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"{status} {name}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 50)
    if all_passed:
        print("üéâ ALL ENHANCEMENTS VALIDATED SUCCESSFULLY!")
        print("‚úÖ ChoyAI is ready for advanced AI operations")
    else:
        print("‚ö†Ô∏è  Some validations failed - check implementations")
    
    print("=" * 50)
    return 0 if all_passed else 1

if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Validation interrupted by user")
        sys.exit(130)
    except Exception as e:
        print(f"\n\nüí• Validation crashed: {e}")
        sys.exit(1)
